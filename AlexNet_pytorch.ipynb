{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfX1mfYmNfKaZzWGLDWpj4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/issam9/alexnet-implementation-pytorch/blob/main/AlexNet_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WhfIjZWkEJ2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torchvision \n",
        "import torchvision.transforms as tfms\n",
        "from fastai.vision import *\n",
        "import tqdm"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1AbSx5a1GRG",
        "outputId": "8dc7e4c8-da48-4fc6-d004-755a2200962a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WOqdJf0kh34",
        "outputId": "642e948c-9361-4abb-d175-a063f13f438c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# imagenette is a small version of imagenet it contains only 10 classes\n",
        "path = untar_data(URLs.IMAGENETTE)\n",
        "path.ls()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imagenette2/val'),\n",
              " PosixPath('/root/.fastai/data/imagenette2/train')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7_vhGwHtreG"
      },
      "source": [
        "transform = tfms.Compose(\n",
        "    [tfms.ToTensor(),\n",
        "     tfms.Resize(227),\n",
        "     tfms.CenterCrop(227),\n",
        "     tfms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) # imagenet stats"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcgT4lDCvIXO"
      },
      "source": [
        "trainset = torchvision.datasets.ImageFolder(path/'train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "validset = torchvision.datasets.ImageFolder(path/'val', transform=transform)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9x4ntvHzTYO"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super().__init__()\n",
        "        # input should be of size (3 x 227 x 227)\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4), #(96 x 55 x 55)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2), \n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), #(96 x 27 x 27)\n",
        "            nn.Conv2d(96, 256, 5, padding=2), # (256 x 27 x 27)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5, alpha=1e-4, beta=0.75, k=2),\n",
        "            nn.MaxPool2d(3, stride=2), # (256 x 13 x 13)\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1), #(384 x 13 x 13)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1), #(384 x 13 x 13)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # (256 x 13 x 13)\n",
        "            nn.MaxPool2d(3, stride=2), #(256 x 6 x 6)\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "      \n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256*6*6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5), \n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x:torch.Tensor):\n",
        "      \n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x "
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXEBPp4A0X64"
      },
      "source": [
        "alexnet = AlexNet(10).to(device)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56CIIU8S1MB-"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(alexnet.parameters(), lr=0.001)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvTx0eLvLnnd"
      },
      "source": [
        "train_len = len(trainloader)\n",
        "valid_len = len(validloader)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2Tb2gLqC9Kg"
      },
      "source": [
        "for epoch in range(20):\n",
        "  print(f'training on epoch {epoch}...')\n",
        "  alexnet.train()\n",
        "  \n",
        "  sum_loss = 0.0\n",
        "  for imgs, labels in tqdm.tqdm(trainloader, position=0):\n",
        "\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "    #zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = alexnet(imgs)\n",
        "\n",
        "    #calculate loss\n",
        "    train_loss = criterion(output, labels)\n",
        "\n",
        "    # backward propagation\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    sum_loss+=train_loss.item()\n",
        "  \n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    _, preds = torch.max(output, dim=1)\n",
        "    total+=labels.size(0)\n",
        "    correct += torch.sum(preds == labels).item()\n",
        "    print(f'\\n epoch : {epoch+1} \\t training loss : {sum_loss/train_len} \\t training accuracy : {correct/total} ')\n",
        "\n",
        "\n",
        "  alexnet.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  sum_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    for imgs, labels in tqdm.tqdm(validloader, position=0):\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "      output = alexnet(imgs)\n",
        "      valid_loss = criterion(output, labels)\n",
        "\n",
        "      sum_loss+=valid_loss.item()\n",
        "\n",
        "      _, preds = torch.max(output, dim=1)\n",
        "      total += labels.size(0)\n",
        "      correct += torch.sum(preds == labels).item()\n",
        "\n",
        "  print(f'\\n epoch : {epoch+1} \\t valid loss : {sum_loss/valid_len} \\t valid accuracy : {correct/total} ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Ois2qiDCN2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}